{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: light\n",
    "#       format_version: '1.5'\n",
    "#       jupytext_version: 1.13.7\n",
    "#   kernelspec:\n",
    "#     display_name: Python 3 (ipykernel)\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94caddb",
   "metadata": {},
   "source": [
    "# Notebook 2: NLP Extraction Testing & Debugging\n",
    "\n",
    "**Objective:** Load the spaCy model and test the NLP extraction pipeline on specific examples or subsets of notes. Useful for debugging entity recognition, normalization, severity linking, and negation detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6997147",
   "metadata": {},
   "source": [
    "## Cell 1: Setup Project Root Path & Core Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c49e19e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import spacy # Import spacy directly for testing\n",
    "import warnings\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244746e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Add project root to sys.path ---\n",
    "# Get the current working directory of the notebook (e.g., C:\\...\\ClinNLP\\notebooks)\n",
    "notebook_dir = os.getcwd()\n",
    "# Go up one level to get the project root directory (e.g., C:\\...\\ClinNLP)\n",
    "project_root = os.path.dirname(notebook_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd64ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the project root is already in sys.path, if not, add it\n",
    "if project_root not in sys.path:\n",
    "    print(f\"Adding project root to sys.path: {project_root}\")\n",
    "    sys.path.insert(0, project_root) # Use insert(0, ...) to prioritize this path\n",
    "else:\n",
    "    print(f\"Project root already in sys.path: {project_root}\")\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c549b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71598568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import modules from src and config ---\n",
    "try:\n",
    "    # This code is indented (usually 4 spaces)\n",
    "    from src.config import (NOTES_DATA_PATH, AE_NORMALIZATION_MAP,\n",
    "                           SEVERITY_TERMS, SEVERITY_PATTERNS, AE_LABELS, DRUG_LABELS,\n",
    "                           NEGSPACY_AVAILABLE) # Import NEGSPACY_AVAILABLE flag\n",
    "    from src.data_processing import load_notes_data\n",
    "    from src.nlp_extraction import (setup_nlp, link_ae_severity_improved,\n",
    "                                    extract_entities_advanced_nlp) # Import setup and main function\n",
    "\n",
    "    print(\"\\nSuccessfully imported modules from 'src' and config.\")\n",
    "    print(f\"Project Root: {project_root}\")\n",
    "\n",
    "# This 'except' is NOT indented, aligned with 'try'\n",
    "except ImportError as e:\n",
    "    # This code IS indented\n",
    "    print(f\"\\nERROR: Could not import from 'src'.\")\n",
    "    print(f\"Ensure the notebook is inside the 'notebooks' directory\")\n",
    "    print(f\"and the 'src' directory exists at the project root: {project_root}\")\n",
    "    print(f\"ImportError: {e}\")\n",
    "    # raise e\n",
    "# This 'except' is also NOT indented, aligned with 'try'\n",
    "except Exception as e:\n",
    "    # This code IS indented\n",
    "    print(f\"An unexpected error occurred during import: {e}\")\n",
    "    # raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20001dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "except ImportError as e:\n",
    "    print(f\"\\nERROR: Could not import from 'src'.\")\n",
    "    print(f\"Ensure the notebook is inside the 'notebooks' directory\")\n",
    "    print(f\"and the 'src' directory exists at the project root: {project_root}\")\n",
    "    print(f\"ImportError: {e}\")\n",
    "    # raise e\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during import: {e}\")\n",
    "    # raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e820976",
   "metadata": {},
   "source": [
    "## Cell 2: Load Sample Notes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30481205",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoading notes data...\")\n",
    "notes_df = None # Initialize\n",
    "notes_sample_df = None # Initialize sample df too\n",
    "\n",
    "try:\n",
    "    # This line is indented under 'try'\n",
    "    notes_df = load_notes_data(NOTES_DATA_PATH)\n",
    "    print(f\"\\nLoaded {len(notes_df)} notes.\")\n",
    "    print(notes_df.head())\n",
    "\n",
    "    # --- !! SELECT A SMALL SAMPLE FOR TESTING !! ---\n",
    "    # This 'if' is indented under 'try'\n",
    "    if len(notes_df) > 50: # Only sample if df is large\n",
    "        # This 'print' is indented under 'if'\n",
    "        print(\"\\nSelecting a small sample of 20 notes for detailed testing...\")\n",
    "        # This assignment MUST be indented under 'if'\n",
    "        notes_sample_df = notes_df.sample(n=20, random_state=42)\n",
    "    # This 'else' MUST be aligned vertically with 'if'\n",
    "    else:\n",
    "        # This assignment MUST be indented under 'else'\n",
    "        notes_sample_df = notes_df\n",
    "\n",
    "    # This 'print' should be aligned with the 'if/else' block, still inside 'try'\n",
    "    # Add a check to make sure notes_sample_df was created before printing length\n",
    "    if notes_sample_df is not None:\n",
    "        print(f\"\\nUsing sample of {len(notes_sample_df)} notes for testing.\")\n",
    "    else:\n",
    "        print(\"\\nSample DataFrame could not be created (notes_df might be empty).\")\n",
    "\n",
    "# This 'except' MUST be aligned vertically with 'try'\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nERROR: Notes data file not found at {NOTES_DATA_PATH}\")\n",
    "# This 'except' MUST be aligned vertically with 'try'\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred loading notes data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246495aa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nERROR: Notes data file not found at {NOTES_DATA_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred loading notes data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb9eaca",
   "metadata": {},
   "source": [
    "## Cell 3: Setup spaCy Model & Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a1da2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"\\nSetting up spaCy NLP model...\")\n",
    "nlp = None\n",
    "matcher = None\n",
    "if notes_df is not None: # Only setup if data loaded\n",
    "    try:\n",
    "        nlp, matcher = setup_nlp() # Loads model, matcher, negex pipe\n",
    "        print(\"\\nspaCy model and components initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR setting up spaCy model: {e}\")\n",
    "else:\n",
    "    print(\"Skipping spaCy setup because notes data failed to load.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c6b7f",
   "metadata": {},
   "source": [
    "## Cell 4: Process a Single Note Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ccf893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a note index or note_id from your sample/full dataframe\n",
    "example_note_index = notes_sample_df.index[0] if notes_sample_df is not None and not notes_sample_df.empty else None\n",
    "# Or set a specific note_id if you know one: example_note_id = 'some_note_123'\n",
    "# example_note_index = notes_df[notes_df['note_id'] == example_note_id].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf9455d-9f40-4d8f-8994-b7df1910e697",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if nlp and example_note_index is not None:\n",
    "    example_text = notes_sample_df.loc[example_note_index, 'note_text']\n",
    "    example_note_id = notes_sample_df.loc[example_note_index, 'note_id']\n",
    "    print(f\"\\n--- Processing Example Note (ID: {example_note_id}) ---\")\n",
    "    print(\"Text:\")\n",
    "    print(example_text)\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Process the text with the loaded nlp object\n",
    "    doc = nlp(example_text)\n",
    "\n",
    "    print(\"\\nEntities Found (doc.ents):\")\n",
    "    if not doc.ents:\n",
    "        print(\"  No entities found by the model.\")\n",
    "    for ent in doc.ents:\n",
    "        negation_status = \"\"\n",
    "        if NEGSPACY_AVAILABLE and hasattr(ent._, 'negex'):\n",
    "             negation_status = f\" | Negated: {ent._.negex}\"\n",
    "        elif ent.label_ in AE_LABELS and not NEGSPACY_AVAILABLE:\n",
    "             negation_status = \" | Negation: (negspacy unavailable)\"\n",
    "\n",
    "        print(f\"  - Text: '{ent.text}' | Label: {ent.label_}{negation_status}\")\n",
    "\n",
    "    print(\"\\nSeverity Terms Found (matcher):\")\n",
    "    severity_matches = matcher(doc)\n",
    "    if not severity_matches:\n",
    "        print(\"  No severity terms found by the matcher.\")\n",
    "    for match_id, start, end in severity_matches:\n",
    "        span = Span(doc, start, end, label=nlp.vocab.strings[match_id])\n",
    "        print(f\"  - Text: '{span.text}' | Label: {span.label_} | Position: ({start}-{end})\")\n",
    "\n",
    "    print(\"\\nLinking AEs and Severity (Simple Proximity):\")\n",
    "    ae_entities = [ent for ent in doc.ents if ent.label_ in AE_LABELS]\n",
    "    if not ae_entities:\n",
    "        print(\"  No AE entities found to link severity.\")\n",
    "    else:\n",
    "        ae_severity_links = link_ae_severity_improved(doc, ae_entities, severity_matches)\n",
    "        for ae, linked_info in ae_severity_links.items():\n",
    "            print(f\"  - AE: '{ae.text}' -> Severity Term: '{linked_info['severity_term']}' (Grade: {linked_info['severity_grade']})\")\n",
    "\n",
    "    print(\"\\nNormalization Check:\")\n",
    "    if not ae_entities:\n",
    "        print(\"  No AE entities found to normalize.\")\n",
    "    else:\n",
    "        for ent in ae_entities:\n",
    "             original_text = ent.text.lower().strip()\n",
    "             normalized_text = AE_NORMALIZATION_MAP.get(original_text, original_text) # Use default if not found\n",
    "             if original_text != normalized_text:\n",
    "                  print(f\"  - Original: '{original_text}' -> Normalized: '{normalized_text}'\")\n",
    "             # else:\n",
    "             #      print(f\"  - Original: '{original_text}' -> Normalized: '{normalized_text}' (No change)\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping single note processing (NLP model not loaded or no example index).\")\n",
    "\n",
    "## Cell 5: Run Full Extraction Pipeline on the Small Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0756565b",
   "metadata": {},
   "source": [
    "This uses the main extraction function from nlp_extraction.py on the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee699a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if notes_sample_df is not None and not notes_sample_df.empty:\n",
    "    print(f\"\\n--- Running full extraction pipeline on sample of {len(notes_sample_df)} notes ---\")\n",
    "    try:\n",
    "        # Rerun setup_nlp just in case it wasn't run or failed before\n",
    "        if not nlp:\n",
    "             nlp, matcher = setup_nlp()\n",
    "\n",
    "        if nlp: # Proceed only if NLP setup succeeded\n",
    "            sample_nlp_results_df = extract_entities_advanced_nlp(notes_sample_df)\n",
    "\n",
    "            if not sample_nlp_results_df.empty:\n",
    "                print(f\"\\nExtraction on sample completed. Found {len(sample_nlp_results_df)} affirmative entities.\")\n",
    "                print(\"Sample results from full pipeline run on sample:\")\n",
    "                print(sample_nlp_results_df[['note_id', 'entity_type', 'entity_text', 'severity_grade']].head(10))\n",
    "\n",
    "                # Further inspection of results\n",
    "                print(\"\\nChecking sample results for specific conditions:\")\n",
    "                print(\"AEs with Severity:\")\n",
    "                print(sample_nlp_results_df[sample_nlp_results_df['severity_grade'].notna() & sample_nlp_results_df['entity_type'].isin(AE_LABELS)].head())\n",
    "                print(\"\\nNormalized AEs:\")\n",
    "                print(sample_nlp_results_df[sample_nlp_results_df['entity_text_original'] != sample_nlp_results_df['entity_text']].head())\n",
    "\n",
    "            else:\n",
    "                print(\"\\nWarning: Full extraction on sample yielded no affirmative entities.\")\n",
    "        else:\n",
    "            print(\"Skipping full extraction on sample because NLP setup failed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during full extraction pipeline run on sample: {e}\")\n",
    "else:\n",
    "    print(\"\\nSkipping full extraction on sample (sample data not available).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f4e77",
   "metadata": {},
   "source": [
    "## Cell 6: Further Testing (Add more specific tests as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f94896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Test a specific normalization rule\n",
    "test_term = \"low white count\"\n",
    "normalized = AE_NORMALIZATION_MAP.get(test_term, test_term)\n",
    "print(f\"\\nTesting normalization for '{test_term}': Result = '{normalized}'\")\n",
    "# Assert statement for automated testing (won't stop notebook execution on fail by default)\n",
    "try:\n",
    "    assert normalized == \"Neutropenia\"\n",
    "    print(\"  Assertion PASSED.\")\n",
    "except AssertionError:\n",
    "    print(\"  Assertion FAILED.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Test a specific severity term\n",
    "test_sev = \"g3\"\n",
    "grade = SEVERITY_TERMS.get(test_sev, None)\n",
    "print(f\"Testing severity for '{test_sev}': Result = {grade}\")\n",
    "try:\n",
    "    assert grade == 3\n",
    "    print(\"  Assertion PASSED.\")\n",
    "except AssertionError:\n",
    "    print(\"  Assertion FAILED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9258dd12",
   "metadata": {},
   "source": [
    "Add more tests for edge cases, different sentence structures, negation patterns etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e937eae5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n--- NLP Testing Notebook Finished ---\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
